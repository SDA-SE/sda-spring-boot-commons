{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SDA Spring Boot Commons \u00b6 A set of libraries to bootstrap Spring Boot services easily that follow the patterns and specifications promoted by the SDA SE. Features \u00b6 Starter Description sda-commons-starter-web Provides the required features for an SDA-compliant microservice including OIDC authentication, OPA authorization, health checks, OpenTelemetry, Prometheus metrics and hardening the service . sda-commons-starter-mongodb Provides default configuration based on the org.springframework.boot:spring-boot-starter-data-mongodb sda-commons-starter-kafka Provides default producer und consumer configuration based on org.springframework.kafka:spring-kafka sda-commons-starter-s3 Provides features for dealing with the Amazon S3 file storage The provided documentation aims to provide SDA-specific information. All other information are referenced in the Spring and Spring Boot documentation . Getting started \u00b6 Each starter is provided as an isolated library and relies on the Spring Boot and Spring Cloud dependency management. Most of the starters themselves include some starters provided by Spring or the community. When using any sda-spring-boot-commons starter make sure to include the provided dependency management. The provided dependency management is based on the Spring Boot and Spring Cloud dependency management to align transitive dependencies with the provided Spring versions. 1 2 3 4 5 6 7 8 9 10 11 project . ext { sdaSpringCommonsVersions = '0.11.0' } dependencies { implementation enforcedPlatform ( \"org.sdase.commons.spring.boot:sda-commons-dependencies:$sdaSpringCommonsVersions\" ) implementation enforcedPlatform ( \"org.sdase.commons.spring.boot:sda-commons-bom:$sdaSpringCommonsVersions\" ) implementation 'org.sdase.commons.spring.boot:sda-commons-starter-web' testImplementation \"org.sdase.commons.spring.boot:sda-commons-web-testing\" } Artifacts of SDA Spring Boot Commons are available at Maven Central since release 0.11.2 . Static directories \u00b6 Since Spring Boot runs in an embedded Tomcat server, it needs some tmp directories to support the container run in a readonly file system. Therefore, your application need to set a folder called static and a folder structure tmp/tomcat in the root directory of your container. In order to do so, create a folder static and tmp/tomcat on src/main/jib . If you use non-root docker images, your jib config in your build.gradle file must include container.workingDirectory='/' , so jib will use the root folder to create the sub folders, e.g: 1 2 3 4 jib { from.image = 'gcr.io/distroless/java17-debian11:nonroot' container.workingDirectory='/' } When the container's image is generated with gradlew jibDockerBuild , these folders will be copied to the container. In case you need the tmp folder to be writable, you can mount a volume in your container. The default path is /tmp/tomcat , but you can overwrite it setting the environment variable pointing to your folder: 1 SERVER_TOMCAT_BASEDIR=/path-to-your-folder","title":"Overview"},{"location":"#sda-spring-boot-commons","text":"A set of libraries to bootstrap Spring Boot services easily that follow the patterns and specifications promoted by the SDA SE.","title":"SDA Spring Boot Commons"},{"location":"#features","text":"Starter Description sda-commons-starter-web Provides the required features for an SDA-compliant microservice including OIDC authentication, OPA authorization, health checks, OpenTelemetry, Prometheus metrics and hardening the service . sda-commons-starter-mongodb Provides default configuration based on the org.springframework.boot:spring-boot-starter-data-mongodb sda-commons-starter-kafka Provides default producer und consumer configuration based on org.springframework.kafka:spring-kafka sda-commons-starter-s3 Provides features for dealing with the Amazon S3 file storage The provided documentation aims to provide SDA-specific information. All other information are referenced in the Spring and Spring Boot documentation .","title":"Features"},{"location":"#getting-started","text":"Each starter is provided as an isolated library and relies on the Spring Boot and Spring Cloud dependency management. Most of the starters themselves include some starters provided by Spring or the community. When using any sda-spring-boot-commons starter make sure to include the provided dependency management. The provided dependency management is based on the Spring Boot and Spring Cloud dependency management to align transitive dependencies with the provided Spring versions. 1 2 3 4 5 6 7 8 9 10 11 project . ext { sdaSpringCommonsVersions = '0.11.0' } dependencies { implementation enforcedPlatform ( \"org.sdase.commons.spring.boot:sda-commons-dependencies:$sdaSpringCommonsVersions\" ) implementation enforcedPlatform ( \"org.sdase.commons.spring.boot:sda-commons-bom:$sdaSpringCommonsVersions\" ) implementation 'org.sdase.commons.spring.boot:sda-commons-starter-web' testImplementation \"org.sdase.commons.spring.boot:sda-commons-web-testing\" } Artifacts of SDA Spring Boot Commons are available at Maven Central since release 0.11.2 .","title":"Getting started"},{"location":"#static-directories","text":"Since Spring Boot runs in an embedded Tomcat server, it needs some tmp directories to support the container run in a readonly file system. Therefore, your application need to set a folder called static and a folder structure tmp/tomcat in the root directory of your container. In order to do so, create a folder static and tmp/tomcat on src/main/jib . If you use non-root docker images, your jib config in your build.gradle file must include container.workingDirectory='/' , so jib will use the root folder to create the sub folders, e.g: 1 2 3 4 jib { from.image = 'gcr.io/distroless/java17-debian11:nonroot' container.workingDirectory='/' } When the container's image is generated with gradlew jibDockerBuild , these folders will be copied to the container. In case you need the tmp folder to be writable, you can mount a volume in your container. The default path is /tmp/tomcat , but you can overwrite it setting the environment variable pointing to your folder: 1 SERVER_TOMCAT_BASEDIR=/path-to-your-folder","title":"Static directories"},{"location":"kafka/","text":"sda-commons-kafka-starter \u00b6 The sda-commons-kafka-starter provides autoconfigured Kafka producer and consumer configuration. Based on: - org.springframework.boot:spring-boot-starter - org.springframework.boot:spring-boot-starter-validation - org.springframework.kafka:spring-kafka Configuration \u00b6 Property Description Default Example Env sda.kafka.consumer.retry.initialBackOffInterval int The initial backoff of the retry in ms 1000 1500 SDA_KAFKA_CONSUMER_RETRY_INITIAL_BACKOFF_INTERVALL sda.kafka.consumer.retry.maxBackOffInterval int The max backoff interval in ms 4000 5000 SDA_KAFKA_CONSUMER_RETRY_MAX_BACKOFF_INTERVALL sda.kafka.consumer.retry.backOffMultiplier int The multiplier beginning with the initial backoff 2 1.5 SDA_KAFKA_CONSUMER_RETRY_INITIAL_BACKOFF_INTERVALL sda.kafka.consumer.retry.maxRetries int Max retries consuming the offset 4 10 SDA_KAFKA_CONSUMER_RETRY_INITIAL_MAXRETRIES sda.kafka.consumer.dlt.pattern string Pattern of consumer dead letter topic. <topic> will be replaced by topic name prefix-<topic> SDA_KAFKA_CONSUMER_DLT_PATTERN management.health.kafka.enabled boolean Flag to enable kafka health check true false MANAGEMENT_HEALTH_KAFKA_ENABLED management.health.kafka.timeout duration Allowed duration for health check to finish 4s 5000ms MANAGEMENT_HEALTH_KAFKA_TIMEOUT For further information have a look to the Spring Kafka reference documentation . Consumer configuration \u00b6 The autoconfigured consumer configuration provides several ConcurrentKafkaListenerContainerFactory<String, ?> which can be referenced in @KafkaListener annotated methods. SdaKafkaListenerContainerFactory.LOG_ON_FAILURE Simply logs the exception; with a record listener, the remaining records from the previous poll are passed to the listener. SdaKafkaListenerContainerFactory.RETRY_AND_LOG Skips record that keeps failing after sda.kafka.consumer.retry.maxRetries (default: 4 ) and log exception. SdaKafkaListenerContainerFactory.RETRY_AND_DLT Skips record that keeps failing after sda.kafka.consumer.retry.maxRetries (default: 4) and produces failed record to topic with .DLT suffix. By default, the dead-letter record is sent to a topic named .DLT (the original topic name suffixed with .DLT) and to the same partition as the original record. Therefore, when you use the default configuration, the dead-letter topic must have at least as many partitions as the original topic. The spring default DLT naming convention can be overwritten using the sda.kafka.consumer.dlt.pattern property. The pattern must contain <topic> , which will be replaced by the actual topic name. To skip retry for specific business errors, you can throw the custom NotRetryableKafkaException . Each containerFactory expects a message key as String and the message payload of any type. The payload is deserialized as byte array and converted with the ByteArrayJsonMessageConverter . The ack mode for offsets is per default RECORD where the offset after each record is processed by the listener. 1 2 3 4 5 6 7 8 9 @KafkaListener ( topics = \"TestTopic\" , containerFactory = SdaKafkaListenerContainerFactory . RETRY_AND_LOG ) public void retryAndLog ( @Payload @Valid Message message ) { // doSomething if ( businessError ) { throw new NotRetryableKafkaException (); } } Defaults \u00b6 1 2 3 4 5 6 7 spring.kafka.consumer.group-id = default spring.kafka.consumer.auto-offset-reset = earliest spring.kafka.consumer.key-deserializer = org.springframework.kafka.support.serializer.ErrorHandlingDeserializer spring.kafka.consumer.value-deserializer = org.springframework.kafka.support.serializer.ErrorHandlingDeserializer spring.kafka.consumer.properties.spring.deserializer.key.delegate.class = org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.properties.spring.deserializer.value.delegate.class = org.apache.kafka.common.serialization.ByteArrayDeserializer spring.kafka.consumer.properties.spring.json.trusted.packages = * Make sure to overwrite spring.kafka.consumer.group-id in your application.properties otherwise you could have conflicts with other services using default . Producer configuration \u00b6 The autoconfigured producer configuration provides a preconfigured KafkaTemplate for producing messages with String key and payload as json . You just need to autowire the KafkaTemplate and you are ready to go. Defaults \u00b6 1 2 spring.kafka.producer.key-serializer = org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer = org.springframework.kafka.support.serializer.JsonSerializer Configuration properties \u00b6 spring.kafka.bootstrap.servers string Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster Example: kafka-broker:9092\" Default: localhost:9092 spring.kafka.security.protocol string The security protocol used by Kafka. Please note that SASL mechanism requires some manual configuration. Example: PLAINTEXT or SSL Default: PLAINTEXT spring.kafka.ssl.key-store-location string Location of the SSL keystore file Example: file:/kafka/kafka.client.keystore.jks Default: `` spring.kafka.ssl.key-store-password string Password for the SSL keystore file Example: s3cret Default: `` spring.kafka.ssl.trust-store-location\u00b4 string Location of the SSL truststore file Example: file:/kafka-certs/kafka.client.keystore.jks Default: `` Sspring.kafka.ssl.trust-store-password string Password for the SSL truststore file Example: s3cret Default: `` Consumers \u00b6 spring.kafka.consumer.group-id string Consumer group name of Kafka Consumer Example: myConsumer Default: default","title":"Kafka"},{"location":"kafka/#sda-commons-kafka-starter","text":"The sda-commons-kafka-starter provides autoconfigured Kafka producer and consumer configuration. Based on: - org.springframework.boot:spring-boot-starter - org.springframework.boot:spring-boot-starter-validation - org.springframework.kafka:spring-kafka","title":"sda-commons-kafka-starter"},{"location":"kafka/#configuration","text":"Property Description Default Example Env sda.kafka.consumer.retry.initialBackOffInterval int The initial backoff of the retry in ms 1000 1500 SDA_KAFKA_CONSUMER_RETRY_INITIAL_BACKOFF_INTERVALL sda.kafka.consumer.retry.maxBackOffInterval int The max backoff interval in ms 4000 5000 SDA_KAFKA_CONSUMER_RETRY_MAX_BACKOFF_INTERVALL sda.kafka.consumer.retry.backOffMultiplier int The multiplier beginning with the initial backoff 2 1.5 SDA_KAFKA_CONSUMER_RETRY_INITIAL_BACKOFF_INTERVALL sda.kafka.consumer.retry.maxRetries int Max retries consuming the offset 4 10 SDA_KAFKA_CONSUMER_RETRY_INITIAL_MAXRETRIES sda.kafka.consumer.dlt.pattern string Pattern of consumer dead letter topic. <topic> will be replaced by topic name prefix-<topic> SDA_KAFKA_CONSUMER_DLT_PATTERN management.health.kafka.enabled boolean Flag to enable kafka health check true false MANAGEMENT_HEALTH_KAFKA_ENABLED management.health.kafka.timeout duration Allowed duration for health check to finish 4s 5000ms MANAGEMENT_HEALTH_KAFKA_TIMEOUT For further information have a look to the Spring Kafka reference documentation .","title":"Configuration"},{"location":"kafka/#consumer-configuration","text":"The autoconfigured consumer configuration provides several ConcurrentKafkaListenerContainerFactory<String, ?> which can be referenced in @KafkaListener annotated methods. SdaKafkaListenerContainerFactory.LOG_ON_FAILURE Simply logs the exception; with a record listener, the remaining records from the previous poll are passed to the listener. SdaKafkaListenerContainerFactory.RETRY_AND_LOG Skips record that keeps failing after sda.kafka.consumer.retry.maxRetries (default: 4 ) and log exception. SdaKafkaListenerContainerFactory.RETRY_AND_DLT Skips record that keeps failing after sda.kafka.consumer.retry.maxRetries (default: 4) and produces failed record to topic with .DLT suffix. By default, the dead-letter record is sent to a topic named .DLT (the original topic name suffixed with .DLT) and to the same partition as the original record. Therefore, when you use the default configuration, the dead-letter topic must have at least as many partitions as the original topic. The spring default DLT naming convention can be overwritten using the sda.kafka.consumer.dlt.pattern property. The pattern must contain <topic> , which will be replaced by the actual topic name. To skip retry for specific business errors, you can throw the custom NotRetryableKafkaException . Each containerFactory expects a message key as String and the message payload of any type. The payload is deserialized as byte array and converted with the ByteArrayJsonMessageConverter . The ack mode for offsets is per default RECORD where the offset after each record is processed by the listener. 1 2 3 4 5 6 7 8 9 @KafkaListener ( topics = \"TestTopic\" , containerFactory = SdaKafkaListenerContainerFactory . RETRY_AND_LOG ) public void retryAndLog ( @Payload @Valid Message message ) { // doSomething if ( businessError ) { throw new NotRetryableKafkaException (); } }","title":"Consumer configuration"},{"location":"kafka/#defaults","text":"1 2 3 4 5 6 7 spring.kafka.consumer.group-id = default spring.kafka.consumer.auto-offset-reset = earliest spring.kafka.consumer.key-deserializer = org.springframework.kafka.support.serializer.ErrorHandlingDeserializer spring.kafka.consumer.value-deserializer = org.springframework.kafka.support.serializer.ErrorHandlingDeserializer spring.kafka.consumer.properties.spring.deserializer.key.delegate.class = org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.properties.spring.deserializer.value.delegate.class = org.apache.kafka.common.serialization.ByteArrayDeserializer spring.kafka.consumer.properties.spring.json.trusted.packages = * Make sure to overwrite spring.kafka.consumer.group-id in your application.properties otherwise you could have conflicts with other services using default .","title":"Defaults"},{"location":"kafka/#producer-configuration","text":"The autoconfigured producer configuration provides a preconfigured KafkaTemplate for producing messages with String key and payload as json . You just need to autowire the KafkaTemplate and you are ready to go.","title":"Producer configuration"},{"location":"kafka/#defaults_1","text":"1 2 spring.kafka.producer.key-serializer = org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer = org.springframework.kafka.support.serializer.JsonSerializer","title":"Defaults"},{"location":"kafka/#configuration-properties","text":"spring.kafka.bootstrap.servers string Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster Example: kafka-broker:9092\" Default: localhost:9092 spring.kafka.security.protocol string The security protocol used by Kafka. Please note that SASL mechanism requires some manual configuration. Example: PLAINTEXT or SSL Default: PLAINTEXT spring.kafka.ssl.key-store-location string Location of the SSL keystore file Example: file:/kafka/kafka.client.keystore.jks Default: `` spring.kafka.ssl.key-store-password string Password for the SSL keystore file Example: s3cret Default: `` spring.kafka.ssl.trust-store-location\u00b4 string Location of the SSL truststore file Example: file:/kafka-certs/kafka.client.keystore.jks Default: `` Sspring.kafka.ssl.trust-store-password string Password for the SSL truststore file Example: s3cret Default: ``","title":"Configuration properties"},{"location":"kafka/#consumers","text":"spring.kafka.consumer.group-id string Consumer group name of Kafka Consumer Example: myConsumer Default: default","title":"Consumers"},{"location":"mongodb/","text":"sda-commons-mongodb-starter \u00b6 The sda-commons-mongodb-starter provides several autoconfigured features including: - The Read/Write ZonedDateTime converter - Automatic index creation Based on: - org.springframework.boot:spring-boot-starter-data-mongodb For further documentation please have a look at the Spring Data MongoDB reference documentation . Main Configuration \u00b6 Property Description Default Example Env spring.data.mongodb.uri string The MongoDB connection string . mongodb://localhost:27017/test SPRING_DATA_MONGODB_URI Configuration properties \u00b6 spring.data.mongodb.uri string Mongo database URI. Example: mongodb://exampleUser:examplePassword@mongoHost:27017 * Format: mongodb://[username:password@]host1[:port1][,...hostN[:portN]][/[defaultauthdb][?options]] Connection String Options need to be added to the end of the URI e.g. ?ssl=true to enable SSL ?retryWrites=false to disable retryable writes for the connection. ?readPreference=secondardPreferred In most situations, operations read from secondary members, but in situations where the set consists of a single primary (and no other members), the read operation will use the replica set's primary. For further information take a look on Connection String documentation SSL support \u00b6 The mongodb starter can be configured to use ssl when the option ?ssl=true is used. Certificates in PEM format can be mounted in the directory /var/trust/certificates they will be used by the mongodb client. All certificates found in sub-directories will also be loaded. Note that this directory is also configurable through the property sda.caCertificates.certificatesDir .","title":"MongoDB"},{"location":"mongodb/#sda-commons-mongodb-starter","text":"The sda-commons-mongodb-starter provides several autoconfigured features including: - The Read/Write ZonedDateTime converter - Automatic index creation Based on: - org.springframework.boot:spring-boot-starter-data-mongodb For further documentation please have a look at the Spring Data MongoDB reference documentation .","title":"sda-commons-mongodb-starter"},{"location":"mongodb/#main-configuration","text":"Property Description Default Example Env spring.data.mongodb.uri string The MongoDB connection string . mongodb://localhost:27017/test SPRING_DATA_MONGODB_URI","title":"Main Configuration"},{"location":"mongodb/#configuration-properties","text":"spring.data.mongodb.uri string Mongo database URI. Example: mongodb://exampleUser:examplePassword@mongoHost:27017 * Format: mongodb://[username:password@]host1[:port1][,...hostN[:portN]][/[defaultauthdb][?options]] Connection String Options need to be added to the end of the URI e.g. ?ssl=true to enable SSL ?retryWrites=false to disable retryable writes for the connection. ?readPreference=secondardPreferred In most situations, operations read from secondary members, but in situations where the set consists of a single primary (and no other members), the read operation will use the replica set's primary. For further information take a look on Connection String documentation","title":"Configuration properties"},{"location":"mongodb/#ssl-support","text":"The mongodb starter can be configured to use ssl when the option ?ssl=true is used. Certificates in PEM format can be mounted in the directory /var/trust/certificates they will be used by the mongodb client. All certificates found in sub-directories will also be loaded. Note that this directory is also configurable through the property sda.caCertificates.certificatesDir .","title":"SSL support"},{"location":"s3/","text":"sda-commons-s3-starter \u00b6 This library provides features for dealing with the Amazon S3 file storage. Based on: - io.awspring.cloud:spring-cloud-aws-core The configuration class contains two beans, namely: AmazonS3Client : Providing an interface for accessing the S3 object storage. S3BucketRepository : Providing an abstraction for s3 client with simple repository methods. Configuration \u00b6 The following properties are needed for the configuration. Property Description Example Env s3.bucketName string The name of the bucket containing the desired object. myphotos S3_BUCKET_NAME s3.endpoint string The endpoint either with or without the protocol https://s3.eu-west-1.amazonaws.com or s3.eu-west-1.amazonaws.com S3_ENDPOINT s3.region string The region to use for SigV4 signing of requests eu-west-1 S3_REGION s3.secretKey string The AWS secret access key s3cret S3_SECRET_KEY s3.accessKey string The AWS access key s3cretAccess S3_ACCESS_KEY","title":"S3"},{"location":"s3/#sda-commons-s3-starter","text":"This library provides features for dealing with the Amazon S3 file storage. Based on: - io.awspring.cloud:spring-cloud-aws-core The configuration class contains two beans, namely: AmazonS3Client : Providing an interface for accessing the S3 object storage. S3BucketRepository : Providing an abstraction for s3 client with simple repository methods.","title":"sda-commons-s3-starter"},{"location":"s3/#configuration","text":"The following properties are needed for the configuration. Property Description Example Env s3.bucketName string The name of the bucket containing the desired object. myphotos S3_BUCKET_NAME s3.endpoint string The endpoint either with or without the protocol https://s3.eu-west-1.amazonaws.com or s3.eu-west-1.amazonaws.com S3_ENDPOINT s3.region string The region to use for SigV4 signing of requests eu-west-1 S3_REGION s3.secretKey string The AWS secret access key s3cret S3_SECRET_KEY s3.accessKey string The AWS access key s3cretAccess S3_ACCESS_KEY","title":"Configuration"},{"location":"security/","text":"Security Hardening \u00b6 sda-spring-boot-commons changes some default configuration for security reasons. This document provides a brief overview about the addressed risks. Risk: Accessing critical resources from untrusted environments \u00b6 To avoid exposing internal resources, Spring Boot Actuator is configured to listen on a separate port. Health, metrics and other sensitive information can't be exposed to the internet by accident, e.g. by missing to exclude the actuator path. Custom critical resources can be exposed at the management port by implementing org.springframework.boot.actuate.endpoint.web.annotation.RestControllerEndpoint or org.springframework.boot.actuate.endpoint.web.annotation.ControllerEndpoint . Note that there is an open discussion about these annotations. As long as they are not deprecated, it is suggested to use them because the use is most similar to controllers used in regular REST APIs. Risk: Root start \u00b6 If the service is started with extended privileges as the root user, an attacker can more easily attack the operating system after taking over from the container. The default configuration is capable to run as no root, listening to ports 8080 and 8081. Deployment checks must ensure, that the container is not configured with a root user. Risk: Exploitation of HTTP methods \u00b6 The HTTP method TRACE is disabled by default to mitigate Cross Site Tracing . Risk: Loss of source IP address \u00b6 We expect, that services built with sda-spring-boot-commons are deployed behind a proxy, e.g. an Ingress in Kubernetes. This library is configured by default to consider X-Forwarded-* headers to identify the original caller. Risk: Detection of confidential components \u00b6 Knowing the components used in a software makes it easier to look for and exploit specific CVEs. Custom error handlers and other configurations are used to avoid identifiable default output from the framework and its components. Risk: Lack of visibility \u00b6 If there is no visibility, there is no response to an abusive action and attackers can explore risks undisturbed. Logs are written to standard out by default to comply with Kubernetes environments. Prometheus metrics are exposed as expected by SDA environments. Risk: Buffer Overflow \u00b6 The size of request and response headers is limited to 8KiB. The size of a request body is limited to 1 MB by default, chunked encoding is not accepted and the Content-Length request header is required. The limit can be changed . Header \u00b6 By configuring the default headers, the following risks are addressed: Cross-Site Scripting Content interpretation by the browser Content loading in Flash and PDFs Clickjacking Sharing visited URLs with third parties Abuse from Cross-Origin Resource Sharing","title":"Security Hardening"},{"location":"security/#security-hardening","text":"sda-spring-boot-commons changes some default configuration for security reasons. This document provides a brief overview about the addressed risks.","title":"Security Hardening"},{"location":"security/#risk-accessing-critical-resources-from-untrusted-environments","text":"To avoid exposing internal resources, Spring Boot Actuator is configured to listen on a separate port. Health, metrics and other sensitive information can't be exposed to the internet by accident, e.g. by missing to exclude the actuator path. Custom critical resources can be exposed at the management port by implementing org.springframework.boot.actuate.endpoint.web.annotation.RestControllerEndpoint or org.springframework.boot.actuate.endpoint.web.annotation.ControllerEndpoint . Note that there is an open discussion about these annotations. As long as they are not deprecated, it is suggested to use them because the use is most similar to controllers used in regular REST APIs.","title":"Risk: Accessing critical resources from untrusted environments"},{"location":"security/#risk-root-start","text":"If the service is started with extended privileges as the root user, an attacker can more easily attack the operating system after taking over from the container. The default configuration is capable to run as no root, listening to ports 8080 and 8081. Deployment checks must ensure, that the container is not configured with a root user.","title":"Risk: Root start"},{"location":"security/#risk-exploitation-of-http-methods","text":"The HTTP method TRACE is disabled by default to mitigate Cross Site Tracing .","title":"Risk: Exploitation of HTTP methods"},{"location":"security/#risk-loss-of-source-ip-address","text":"We expect, that services built with sda-spring-boot-commons are deployed behind a proxy, e.g. an Ingress in Kubernetes. This library is configured by default to consider X-Forwarded-* headers to identify the original caller.","title":"Risk: Loss of source IP address"},{"location":"security/#risk-detection-of-confidential-components","text":"Knowing the components used in a software makes it easier to look for and exploit specific CVEs. Custom error handlers and other configurations are used to avoid identifiable default output from the framework and its components.","title":"Risk: Detection of confidential components"},{"location":"security/#risk-lack-of-visibility","text":"If there is no visibility, there is no response to an abusive action and attackers can explore risks undisturbed. Logs are written to standard out by default to comply with Kubernetes environments. Prometheus metrics are exposed as expected by SDA environments.","title":"Risk: Lack of visibility"},{"location":"security/#risk-buffer-overflow","text":"The size of request and response headers is limited to 8KiB. The size of a request body is limited to 1 MB by default, chunked encoding is not accepted and the Content-Length request header is required. The limit can be changed .","title":"Risk: Buffer Overflow"},{"location":"security/#header","text":"By configuring the default headers, the following risks are addressed: Cross-Site Scripting Content interpretation by the browser Content loading in Flash and PDFs Clickjacking Sharing visited URLs with third parties Abuse from Cross-Origin Resource Sharing","title":"Header"},{"location":"web/","text":"sda-commons-web-starter \u00b6 The sda-commons-web-starter provides several features to provide a service based on the SDA core concepts. Features: - Authentication - Authorization - Http Client - Async Request Context - Jackson Object Mapping - Monitoring - Tracing - Health Checks - Logging - Support for Metadata Context Based on: - org.springframework.boot:spring-boot-starter-web - org.springframework.boot:spring-boot-starter-oauth2-resource-server - org.springframework.boot:spring-boot-starter-oauth2-client - org.springframework.boot:spring-boot-starter-validation - org.springframework.boot:spring-boot-starter-actuator - org.springframework.cloud:spring-cloud-starter-openfeign - org.springframework.boot:spring-boot-starter-validation - org.springframework.cloud:spring-cloud-starter-sleuth - org.springframework.cloud:spring-cloud-sleuth-zipkin Configuration \u00b6 Property Description Default Example Env auth.issuers string Comma separated string of open id discovery key sources with required issuers. https://iam-int.dev.de/auth/realms/123 AUTH_ISSUERS auth.disable boolean Disables authorization checks completely. false true AUTH_DISABLE opa.disable boolean Disables authorization checks with Open Policy Agent completely. false true OPA_DISABLE opa.base.url string The baseUrl of OPA. http://localhost:8181 http://opa-service:8181 OPA_BASE_URL opa.policy.package string The policy package to check for authorization. Defaults to package name of @SpringBootApplication annotated class com.custom.package.name OPA_POLICY_PACKAGE opa.exclude.patterns string Custom excluded paths can be configured as comma separated list of regex. openapi.json and openapi.yaml /customPathOne,/customPathTwo OPA_EXCLUDE_PATTERNS opa.client.connection.timeout string The connection timeout of the client that calls the Open Policy Agent server. 500ms 2s OPA_CLIENT_CONNECTION_TIMEOUT opa.client.timeout string The read timeout of the client that calls the Open Policy Agent server. 500ms 2s OPA_CLIENT_TIMEOUT oidc.client.enabled boolean Enables OIDC Authentication (Client Credentials Flow) for the configured clients. false true OIDC_CLIENT_ENABLED oidc.client.id string The client ID for the registration. `` exampleClient OPA_CLIENT_ID oid.client.secret string The Client secret of the registration. `` s3cret OIDC_CLIENT_SECRET oidc.client.issuer.uri string URI that can either be an OpenID Connect discovery endpoint or an OAuth 2.0 Authorization Server Metadata endpoint defined by RFC 8414. `` https://keycloak.sdadev.sda-se.io/auth/realms/exampleRealm OIDC_CLIENT_ISSUER_URI cors.allowed-origin-patterns string Comma separated list of URL patterns for which CORS requests are allowed. none allowed https://*.all-subdomains.com, https://static-domain.com CORS_ALLOWEDORIGINPATTERNS request.body.max.size size The maximum size allowed for request body data sent by a client. 1 MB 100 KB , 10MB REQUEST_BODY_MAX_SIZE enable.json.logging boolean If logs should be printed as JSON. Note: This config param is not available for application.properties or application.yaml false true ENABLE_JSON_LOGGING For further information have a look at the Spring Boot documentation . Web \u00b6 The list of web configurations: The server.servlet.context-path defaults to /api The server.port defaults to 8080 The managment.server.port defaults to 8081 The openapi.yaml is available under /api/openapi.yaml Please make sure to configure spring.application.name for every service Authentication \u00b6 Spring Security Documentation Enables feature that make a Spring Boot service compliant with the SDA SE Authentication concepts using OIDC. OIDC Authentication can be configured with auth.issuers to provide a comma separated list of trusted issuers. In develop and test environments, the boolean auth.disable may be used to disable authentication. The JWKS URI of each issuer is updated when an unknown Key ID is received and every 5 minutes. The cache of known JWK is invalidated after 15 minutes. This setup allows authenticated and anonymous requests! It is the responsibility of policies provided by the Open Policy Agent to decide about denying anonymous requests. Spring Security is disabled for the Management/Admin Port (default: 8081). Be aware that these port should not be accessible out of the deployment context. This security implementation lacks some features compared to sda-dropwizard-commons : - No configuration of static local public keys to verify the token signature. - No configuration of JWKS URIs to verify the token signature. - The IDP must provide an iss claim that matches the base URI for discovery. - Leeway is not configurable yet. - The client that loads the JWKS is not configurable yet. Authorization \u00b6 Enables feature that make a Spring Boot service compliant with the SDA SE Authorization concepts using Open Policy Agent. The authorization is done by the Open Policy Agent . It can be configured as described in OpaAccessDecisionVoter#OpaAccessDecisionVoter (boolean, String, String, OpaRequestBuilder, RestTemplate, ApplicationContext, io.opentracing.Tracer) and OpaRestTemplateConfiguration#OpaRestTemplateConfiguration(Duration, Duration) . The OPA configuration acts as a client to the Open Policy Agent and is hooked in as request filter ( Access Decision Manager) which is part of the SecurityFilterChain including the OIDC Authentication. Constraints provided with the Open Policy Agent response can be mapped to a custom POJO. If the class extends AbstractConstraints and is annotated with @Constraints it can be @Autowired in @Controllers or @RestControllers . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Constraints public class MyConstraints extends AbstractConstraints { private boolean admin ; public MyConstraints setAdmin ( boolean admin ) { this . admin = admin ; return this ; } public boolean isAdmin () { return admin ; } } 1 2 3 4 5 6 @RestController public class AuthTestApp { @Autowired private MyConstraints myConstraints ; // ... } Additional parameters that are needed for the authorization decision may be provided with custom OpaInputExtensions . Testing \u00b6 The testing module provides aligned test dependencies including Wiremock for external APIs and JUnit extensions to mock or disable authentication and authorization. OPA \u00b6 The OPA configuration requests the policy decision providing the following inputs HTTP path as Array HTTP method as String validated JWT (if available) all request headers Remark to HTTP request headers: The configuration normalizes header names to lower case to simplify handling in OPA since HTTP specification defines header names as case-insensitive. Multivalued headers are not normalized with respect to the representation as list or single string with separator char. They are forwarded as parsed by the framework. Security note: Please be aware while a service might only consider one value of a specific header, the OPA is able to authorize on a array of those. Consider this in your policy when you want to make sure you authorize on the same value that a service might use to evaluate the output. These inputs can be accessed inside a policy .rego -file in this way: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # each policy lies in a package that is referenced in the configuration of the OpaBundle package example # decode the JWT as new variable 'token' token = {\"payload\": payload} { not input.jwt == null io.jwt.decode(input.jwt, [_, payload, _]) } # deny by default default allow = false allow { # allow if path match '/contracts/:anyid' input.path = [\"contracts\", _] # allow if request method 'GET' is used input.httpMethod == \"GET\" # allow if 'claim' exists in the JWT payload token.payload.claim # allow if a request header 'HttpRequestHeaderName' has a certain value input.headers[\"httprequestheadername\"][_] == \"certain-value\" } # set some example constraints constraint1 := true # always true constraint2 := [ \"v2.1\", \"v2.2\" ] # always an array of \"v2.1\" and \"v2.2\" constraint3[token.payload.sub] # always a set that contains the 'sub' claim from the token # or is empty if no token is present The response consists of two parts: The overall allow decision, and optional rules that represent constraints to limit data access within the service. These constraints are fully service dependent and MUST be applied when querying the database or filtering received data. The following listing presents a sample OPA result with a positive allow decision and two constraints, the first with boolean value and second with a list of string values. 1 2 3 4 5 6 7 8 { \"result\" : { \"allow\" : true , \"constraint1\" : true , \"constraint2\" : [ \"v2.1\" , \"v2.2\" ], \"constraint3\" : [ \"my-sub\" ] } } Configuration Properties \u00b6 opa.disable boolean Disables authorization checks with Open Policy Agent completely. In this case access to all resources is granted but no constraints are provided. opa.base.url string The base url of the Open Policy Agent Server. Defaults to http://localhost:8181 . Requests to the server are determined by the base URL and the policy package. Given the default base URL http://localhost:8181 and an example package of com.my.service , the Open Policy Agent server will be requested for authorization decision at http://localhost:8181/v1/data/com/my/package opa.policy.package string The policy package to check for authorization. It will be reformatted to a URL path to request the authorization form the Open Policy Agent server. Example: com.my.service . If the policy package is blank, the package of the application class (the first bean found that is annotated with @SpringBootApplication ) is used as a default. Be aware that moving the class causes a breaking change regarding deployment if the package is not explicitly set. Requests to the server are determined by the base URL and the policy package. Given the default base URL http://localhost:8181 and an example package of com.my.service , the Open Policy Agent server will be requested for authorization decision at http://localhost:8181/v1/data/com/my/package opa.exclude.patterns string /openapi.yaml and /openapi.json are excluded from authorization requirements. Custom excluded paths can be configured as comma separated list of regex. This will overwrite the default excludes of the OpenAPI documentation paths. opa.client.timeout string The read timeout of the client that calls the Open Policy Agent server. Defaults to 500ms. opa.client.connection.timeout string The connection timeout of the client that calls the Open Policy Agent server. Defaults to 500ms. Http Client \u00b6 Enables support for org.springframework.cloud.openfeign.FeignClients that support SDA Platform features like: - passing the Authorization header to downstream services. - passing the Trace-Token header to downstream services. - OIDC client authentication A feign client can be created as interface like this: 1 2 3 4 5 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } Then the spring boot application needs to be annotated with @EnableFeignClients in order for the component scanning to pick up the @FeignClient annotated interfaces like so 1 2 3 4 @EnableFeignClients @SpringBootApplication public class ExampleApplication { (...) } The Partner ODS base url must be configured as http://partner-ods:8080/api in the Spring environment property partnerOds.baseUrl . Detailed configuration like timeouts can be configured with default feign properties in the application.yaml or derived environment properties based on the name attribute of the org.springframework.cloud.openfeign.FeignClient annotation. The client is then available as bean in the Spring context. Authentication forwarding \u00b6 The client can be used within the SDA Platform to path through the received authentication header by adding a configuration: 1 2 3 4 5 6 7 8 9 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" , configuration = { AuthenticationPassThroughClientConfiguration . class } ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } AuthenticationPassThroughClientConfiguration will take the Authorization header from the current request context of the servlet and adds its value to the client request. Trace-Token \u00b6 The client can be used within the SDA Platform to pass through the received Trace-Token header by adding a configuration: 1 2 3 4 5 6 7 8 9 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" , configuration = { SdaTraceTokenClientConfiguration . class } ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } SdaTraceTokenClientConfiguration will take the Trace-Token header from the current request context of the servlet and adds its value to the client request. If no Trace-Token header is present in the current request context, the SdaTraceTokenClientConfiguration will generate a new Trace-Token and pass it to the following requests. OIDC Client \u00b6 If the request context is not always existing, e.g. in cases where a technical user for service-to-service communication is required, the OidcClientRequestConfiguration will request the required OIDC authentication token with the client credentials flow using the configured \"oidc.client.issuer.uri\" , \"oidc.client.id\" and \"oidc.client.secret\" . If the current request context contains the Authorization header, the authentication pass-through will be applied instead. JAX-RS Mapping \u00b6 If you would like to use JAX-RS based web annotations, you just need to apply the feign.jaxrs2.JAXRS2Contract.class to configurations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Path ( \"customers\" ) @FeignClient ( value = \"customerService\" , url = \"${customer.api.base.url}\" , configuration = { OidcClientRequestConfiguration . class , feign . jaxrs2 . JAXRS2Contract . class }) public interface CustomerServiceApi { @POST @Path ( \"/{customerId}/contracts\" ) @Consumes ( APPLICATION_JSON ) void addContract ( @PathParam ( \"customerId\" ) @NotBlank String customerId , Contract contract ); } Configuration properties \u00b6 oidc.client.enabled boolean Enables OIDC Authentication (Client Credentials Flow) for the configured clients. If enabled, provide a client id, secret and an issuer url. Example: true Default: false oidc.client.id string Client ID for the registration Example: oidcClient Default: `` oid.client.secret string Client secret of the registration. Example: s3cret Default: `` oidc.client.issuer.uri string URI that can either be an OpenID Connect discovery endpoint or an OAuth 2.0 Authorization Server Metadata endpoint defined by RFC 8414. Example: https://keycloak.sdadev.sda-se.io/auth/realms/exampleRealm Default: `` Platform Client \u00b6 The Platform Client combines the authentication forwarding, trace token and OIDC configuration without the need to configure each individually. 1 2 3 4 5 6 7 @PlatformClient ( value = \"customerService\" , url = \"${customer.api.base.url}\" ) public interface CustomerServiceApi { // ... } It abstracts some configuration of the FeignClient and is then available as bean as well. Error Handling \u00b6 The sda-commons-web-starter provides a shared ApiError model, to provide a common response error structure for SDA-restful services. Usage \u00b6 Per default, the sda-commons-web-starter autoconfigures a global @ExceptionHandler(ApiException.class) as @ControllerAdvice . As a result, the exception handler is per default provided to every @Controller . Referencing in OpenAPI \u00b6 To provide the common ApiError in the API, you need to reference the class as @Schema . 1 2 3 4 5 @ApiResponse( responseCode = \"422\", description = \"The request could not be processed due to invalid parameters. Details are provided in the error response.\", content = @Content(schema = @Schema(implementation = ApiError.class))) Throwing ApiException \u00b6 When the ApiException is thrown the @ExceptionHandler automatically intercepts the exception and maps the related ResponseEntity . As the result, the controller returns the related http response code and the nested ApiError . 1 2 3 4 5 6 throw ApiException.builder() .httpCode(422) .title(\"Invalid input\") .detail(\"name\", \"name was not null\", \"NOT_NULL\") .cause(e) .build(); In this example the controller would return with http status 422 and body: 1 2 3 4 5 6 7 8 9 10 { \"title\" : \"Invalid input\" , \"invalidParams\" : [ { \"field\" : \"name\" , \"reason\" : \"name was not null\" , \"errorCode\" : \"NOT_NULL\" } ] } Async \u00b6 The default Spring async task executor is autoconfigured to transfer the request attributes of the current request to the Thread running the asynchronous method. Jackson \u00b6 Enables feature that make a Spring Boot service compliant with the SDA SE RESTful API Guide . So far this covers: - the tolerant reader pattern - consistent serialization of java.time.ZonedDateTime compatible to the type date-time of JSON-Schema . It is strongly recommended to use - java.time.LocalDate for dates without time serialized as 2018-09-23 - java.time.ZonedDateTime for date and times serialized as 2018-09-23T14:21:41+01:00 - java.time.Duration for durations with time resolution serialized as P1DT13M - java.time.Period for durations with day resolution serialized as P1Y2D All these types can be read and written in JSON as ISO 8601 formats. Reading java.time.ZonedDateTime is configured to be tolerant so that added nanoseconds or missing milliseconds or missing seconds are supported. @com.fasterxml.jackson.annotation.JsonFormat(pattern = \"...\") should not be used for customizing serialization because it breaks tolerant reading of formatting variants. If a specific field should be serialized with milliseconds, it must be annotated with @com.fasterxml.jackson.databind.annotation.JsonSerialize(using = Iso8601Serializer.WithMillis.class) . If a specific field should be serialized with nanoseconds, it must be annotated with @com.fasterxml.jackson.databind.annotation.JsonSerialize(using = Iso8601Serializer.WithNanos.class) Differences to the known SDA Dropwizard Commons configuration - java.time.ZonedDateTime fields are serialized with seconds by default. There is no other global configuration for java.time.ZonedDateTime serialization available. - Less modules are activated for foreign frameworks . Compared to SDA Dropwizard Commons, GuavaExtrasModule, JodaModule, and CaffeineModule are not registered anymore. - No documented customization of the global com.fasterxml.jackson.databind.ObjectMapper is available right now. - Support for HAL Links and embedding linked resources is not implemented. - Support for YAML is not implemented. - There is no support for field filters . Such filters have been barely used in the SDA SE. Monitoring \u00b6 TODO PROMETHEUS Prometheus Metrics: http://{serviceURL}:{adminPort}/metrics/prometheus Default properties \u00b6 1 2 3 4 5 # Metrics management.endpoints.web.path-mapping.prometheus = metrics/prometheus management.metrics.web.server.request.autotime.enabled = true management.endpoint.prometheus.enabled = true management.endpoint.metrics.enabled = true Tracing \u00b6 Currently, tracing is leveraged by Sleuth in the Spring context. Spring Cloud Sleuth provides Spring Boot autoconfiguration for distributed tracing. Sleuth was built around Zipkin traces and so only supports forwarding them to Zipkin (Thrift via Brave) format for now. But since Jaeger supports Zipkin traces and the OpenTracing Jaeger Spring support is not heavily maintained, there is a need to stick with Sleuth. However, Spring Sleuth is compatible with OpenTracing, so we can use the standardized interfaces, hence the OpenTracing io.opentracing.Tracer is on classpath. Even if Jaeger supports the Zipkin B3 propagation format, Sleuth is forced to just use per default the W3C context propagation Default features are: Adds trace and span ids to the Slf4J MDC, so you can extract all the logs from a given trace or span in a log aggregator. Instruments common ingress and egress points from Spring applications (servlet filter, rest template, scheduled actions, message channels, feign client). The service name is derived from spring.application.name Generate and report Jaeger-compatible traces via HTTP. By default, it sends them to a Zipkin collector on localhost (port 9411). Configure the location of the service using spring.zipkin.base-url . spring.zipkin.base.url string Base url to Zipkin or Zipkin Collector of Jaeger instance. In case of Jaeger, the Zipkin collector must be enabled manually. Example: http://jaeger:9411 Default: http://localhost:9411 spring.zipkin.enabled boolean For testing purposes it's may required to disable tracing. Example: false Default: true Default properties \u00b6 1 2 spring.sleuth.propagation.type = W3C, B3 spring.sleuth.opentracing.enabled = true Health Checks / Actuator \u00b6 Enable features that make a Spring Boot service compliant with the SDA SE Health Checks . Configures the Spring Boot Actuator to be accessible on root path / at default management port 8081 . The following endpoints are provided at the admin management endpoint: Liveness: http://{serviceURL}:{adminPort}/healthcheck/liveness Readiness: http://{serviceURL}:{adminPort}/healthcheck/readiness The readiness group contains the following indicators: ReadinessStateHealthIndicator MongoHealthIndicator , if auto-configured. OpenPolicyAgentHealthIndicator if OPA is enabled for authentication To overwrite the defaults HealthIndicator of the readiness group, you can overwrite the property source: 1 management.endpoint.health.group.readiness.include = readinessState, customCheck Custom health indicators can be easily added to the application context: 1 2 3 4 5 6 7 @Component public class CustomHealthIndicator implements HealthIndicator { @Override public Health health () { return new Health . Builder (). up (). build (); } } The custom health indicator will be available under /healthcheck/custom which is resolved by the prefix of the HealthIndicator implementing component. Default properties \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Actuator management.server.port = 8081 management.server.servlet.context-path = / management.endpoints.web.base-path = / management.endpoints.web.exposure.include = * management.endpoints.enabled-by-default = false # Healthcheck management.endpoint.health.enabled = true management.endpoints.web.path-mapping.health = healthcheck management.endpoint.health.probes.enabled = true # Add the required auto configured health indicators which are supported in org.sdase.commons.spring # See https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints.health.auto-configured-health-indicators # to see the available indicators. If an included HealthIndicator is not autoconfigured, it will be automatically ignored management.endpoint.health.group.readiness.include = readinessState, mongo management.endpoint.health.show-details = always management.endpoint.health.show-components = always Logging \u00b6 The Spring Boot default logging is enabled. Logs are printed to standard out. ENABLE_JSON_LOGGING=true as environment variable or -Denable.json.logging=true as JVM parameter enables output as JSON for structured logs used in log aggregation tools. To enable JSON logging in application.(properties/yaml) , logging.config=classpath:org/sdase/commons/spring/boot/web/logging/logback-json.xml may be used. Metadata Context \u00b6 If you want to make use of the data in the metadata context, you should read the dedicated documentation . If your service is required to support the metadata context but is not interested in the data, continue here: Services that use the sda-spring-boot-commons: - can access the current MetadataContext in their implementation - will automatically load the context from incoming HTTP requests into the thread handling the request, if you register MetadataContextConfiguration - will automatically load the context from consumed Kafka messages into the thread handling the message and the error when handling the message fails when the consumer is configured with one of the provided SdaKafkaConsumerConfiguration - will automatically propagate the context to other services via HTTP when using a platform client that uses the MetadataContextClientConfiguration configuration, e.g: - ```java @FeignClient( value = \"name\", url = \" http://your-api-url \", configuration = { MetadataContextClientConfiguration.class }) public interface ClientWithMetadataConfiguration { 1 2 3 4 @GetMapping(\"/metadata-hello\") Object getSomething(); } ``` will automatically propagate the context in produced Kafka messages when the producer is created with SdaKafkaProducerConfiguration are configurable by the property or environment variable METADATA_FIELDS to be aware of the metadata used in a specific environment Services that interrupt a business process should persist the context from MetadataContext.detachedCurrent() and restore it with MetadataContext.createContext(\u2026) when the process continues. Interrupting a business process means that processing is stopped and continued later in a new thread or even another instance of the service. Most likely, this will happen when a business entity is stored based on a request and loaded later for further processing by a scheduler or due to a new user interaction. In this case, the DetachedMetadataContext must be persisted along with the entity and recreated when the entity is loaded. The DetachedMetadataContext can be defined as field in any MongoDB entity. For services that handle requests or messages in parallel, the metadata context attributes will be automatically transferred to the new threads, if @Async is used.","title":"Web"},{"location":"web/#sda-commons-web-starter","text":"The sda-commons-web-starter provides several features to provide a service based on the SDA core concepts. Features: - Authentication - Authorization - Http Client - Async Request Context - Jackson Object Mapping - Monitoring - Tracing - Health Checks - Logging - Support for Metadata Context Based on: - org.springframework.boot:spring-boot-starter-web - org.springframework.boot:spring-boot-starter-oauth2-resource-server - org.springframework.boot:spring-boot-starter-oauth2-client - org.springframework.boot:spring-boot-starter-validation - org.springframework.boot:spring-boot-starter-actuator - org.springframework.cloud:spring-cloud-starter-openfeign - org.springframework.boot:spring-boot-starter-validation - org.springframework.cloud:spring-cloud-starter-sleuth - org.springframework.cloud:spring-cloud-sleuth-zipkin","title":"sda-commons-web-starter"},{"location":"web/#configuration","text":"Property Description Default Example Env auth.issuers string Comma separated string of open id discovery key sources with required issuers. https://iam-int.dev.de/auth/realms/123 AUTH_ISSUERS auth.disable boolean Disables authorization checks completely. false true AUTH_DISABLE opa.disable boolean Disables authorization checks with Open Policy Agent completely. false true OPA_DISABLE opa.base.url string The baseUrl of OPA. http://localhost:8181 http://opa-service:8181 OPA_BASE_URL opa.policy.package string The policy package to check for authorization. Defaults to package name of @SpringBootApplication annotated class com.custom.package.name OPA_POLICY_PACKAGE opa.exclude.patterns string Custom excluded paths can be configured as comma separated list of regex. openapi.json and openapi.yaml /customPathOne,/customPathTwo OPA_EXCLUDE_PATTERNS opa.client.connection.timeout string The connection timeout of the client that calls the Open Policy Agent server. 500ms 2s OPA_CLIENT_CONNECTION_TIMEOUT opa.client.timeout string The read timeout of the client that calls the Open Policy Agent server. 500ms 2s OPA_CLIENT_TIMEOUT oidc.client.enabled boolean Enables OIDC Authentication (Client Credentials Flow) for the configured clients. false true OIDC_CLIENT_ENABLED oidc.client.id string The client ID for the registration. `` exampleClient OPA_CLIENT_ID oid.client.secret string The Client secret of the registration. `` s3cret OIDC_CLIENT_SECRET oidc.client.issuer.uri string URI that can either be an OpenID Connect discovery endpoint or an OAuth 2.0 Authorization Server Metadata endpoint defined by RFC 8414. `` https://keycloak.sdadev.sda-se.io/auth/realms/exampleRealm OIDC_CLIENT_ISSUER_URI cors.allowed-origin-patterns string Comma separated list of URL patterns for which CORS requests are allowed. none allowed https://*.all-subdomains.com, https://static-domain.com CORS_ALLOWEDORIGINPATTERNS request.body.max.size size The maximum size allowed for request body data sent by a client. 1 MB 100 KB , 10MB REQUEST_BODY_MAX_SIZE enable.json.logging boolean If logs should be printed as JSON. Note: This config param is not available for application.properties or application.yaml false true ENABLE_JSON_LOGGING For further information have a look at the Spring Boot documentation .","title":"Configuration"},{"location":"web/#web","text":"The list of web configurations: The server.servlet.context-path defaults to /api The server.port defaults to 8080 The managment.server.port defaults to 8081 The openapi.yaml is available under /api/openapi.yaml Please make sure to configure spring.application.name for every service","title":"Web"},{"location":"web/#authentication","text":"Spring Security Documentation Enables feature that make a Spring Boot service compliant with the SDA SE Authentication concepts using OIDC. OIDC Authentication can be configured with auth.issuers to provide a comma separated list of trusted issuers. In develop and test environments, the boolean auth.disable may be used to disable authentication. The JWKS URI of each issuer is updated when an unknown Key ID is received and every 5 minutes. The cache of known JWK is invalidated after 15 minutes. This setup allows authenticated and anonymous requests! It is the responsibility of policies provided by the Open Policy Agent to decide about denying anonymous requests. Spring Security is disabled for the Management/Admin Port (default: 8081). Be aware that these port should not be accessible out of the deployment context. This security implementation lacks some features compared to sda-dropwizard-commons : - No configuration of static local public keys to verify the token signature. - No configuration of JWKS URIs to verify the token signature. - The IDP must provide an iss claim that matches the base URI for discovery. - Leeway is not configurable yet. - The client that loads the JWKS is not configurable yet.","title":"Authentication"},{"location":"web/#authorization","text":"Enables feature that make a Spring Boot service compliant with the SDA SE Authorization concepts using Open Policy Agent. The authorization is done by the Open Policy Agent . It can be configured as described in OpaAccessDecisionVoter#OpaAccessDecisionVoter (boolean, String, String, OpaRequestBuilder, RestTemplate, ApplicationContext, io.opentracing.Tracer) and OpaRestTemplateConfiguration#OpaRestTemplateConfiguration(Duration, Duration) . The OPA configuration acts as a client to the Open Policy Agent and is hooked in as request filter ( Access Decision Manager) which is part of the SecurityFilterChain including the OIDC Authentication. Constraints provided with the Open Policy Agent response can be mapped to a custom POJO. If the class extends AbstractConstraints and is annotated with @Constraints it can be @Autowired in @Controllers or @RestControllers . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Constraints public class MyConstraints extends AbstractConstraints { private boolean admin ; public MyConstraints setAdmin ( boolean admin ) { this . admin = admin ; return this ; } public boolean isAdmin () { return admin ; } } 1 2 3 4 5 6 @RestController public class AuthTestApp { @Autowired private MyConstraints myConstraints ; // ... } Additional parameters that are needed for the authorization decision may be provided with custom OpaInputExtensions .","title":"Authorization"},{"location":"web/#testing","text":"The testing module provides aligned test dependencies including Wiremock for external APIs and JUnit extensions to mock or disable authentication and authorization.","title":"Testing"},{"location":"web/#opa","text":"The OPA configuration requests the policy decision providing the following inputs HTTP path as Array HTTP method as String validated JWT (if available) all request headers Remark to HTTP request headers: The configuration normalizes header names to lower case to simplify handling in OPA since HTTP specification defines header names as case-insensitive. Multivalued headers are not normalized with respect to the representation as list or single string with separator char. They are forwarded as parsed by the framework. Security note: Please be aware while a service might only consider one value of a specific header, the OPA is able to authorize on a array of those. Consider this in your policy when you want to make sure you authorize on the same value that a service might use to evaluate the output. These inputs can be accessed inside a policy .rego -file in this way: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # each policy lies in a package that is referenced in the configuration of the OpaBundle package example # decode the JWT as new variable 'token' token = {\"payload\": payload} { not input.jwt == null io.jwt.decode(input.jwt, [_, payload, _]) } # deny by default default allow = false allow { # allow if path match '/contracts/:anyid' input.path = [\"contracts\", _] # allow if request method 'GET' is used input.httpMethod == \"GET\" # allow if 'claim' exists in the JWT payload token.payload.claim # allow if a request header 'HttpRequestHeaderName' has a certain value input.headers[\"httprequestheadername\"][_] == \"certain-value\" } # set some example constraints constraint1 := true # always true constraint2 := [ \"v2.1\", \"v2.2\" ] # always an array of \"v2.1\" and \"v2.2\" constraint3[token.payload.sub] # always a set that contains the 'sub' claim from the token # or is empty if no token is present The response consists of two parts: The overall allow decision, and optional rules that represent constraints to limit data access within the service. These constraints are fully service dependent and MUST be applied when querying the database or filtering received data. The following listing presents a sample OPA result with a positive allow decision and two constraints, the first with boolean value and second with a list of string values. 1 2 3 4 5 6 7 8 { \"result\" : { \"allow\" : true , \"constraint1\" : true , \"constraint2\" : [ \"v2.1\" , \"v2.2\" ], \"constraint3\" : [ \"my-sub\" ] } }","title":"OPA"},{"location":"web/#configuration-properties","text":"opa.disable boolean Disables authorization checks with Open Policy Agent completely. In this case access to all resources is granted but no constraints are provided. opa.base.url string The base url of the Open Policy Agent Server. Defaults to http://localhost:8181 . Requests to the server are determined by the base URL and the policy package. Given the default base URL http://localhost:8181 and an example package of com.my.service , the Open Policy Agent server will be requested for authorization decision at http://localhost:8181/v1/data/com/my/package opa.policy.package string The policy package to check for authorization. It will be reformatted to a URL path to request the authorization form the Open Policy Agent server. Example: com.my.service . If the policy package is blank, the package of the application class (the first bean found that is annotated with @SpringBootApplication ) is used as a default. Be aware that moving the class causes a breaking change regarding deployment if the package is not explicitly set. Requests to the server are determined by the base URL and the policy package. Given the default base URL http://localhost:8181 and an example package of com.my.service , the Open Policy Agent server will be requested for authorization decision at http://localhost:8181/v1/data/com/my/package opa.exclude.patterns string /openapi.yaml and /openapi.json are excluded from authorization requirements. Custom excluded paths can be configured as comma separated list of regex. This will overwrite the default excludes of the OpenAPI documentation paths. opa.client.timeout string The read timeout of the client that calls the Open Policy Agent server. Defaults to 500ms. opa.client.connection.timeout string The connection timeout of the client that calls the Open Policy Agent server. Defaults to 500ms.","title":"Configuration Properties"},{"location":"web/#http-client","text":"Enables support for org.springframework.cloud.openfeign.FeignClients that support SDA Platform features like: - passing the Authorization header to downstream services. - passing the Trace-Token header to downstream services. - OIDC client authentication A feign client can be created as interface like this: 1 2 3 4 5 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } Then the spring boot application needs to be annotated with @EnableFeignClients in order for the component scanning to pick up the @FeignClient annotated interfaces like so 1 2 3 4 @EnableFeignClients @SpringBootApplication public class ExampleApplication { (...) } The Partner ODS base url must be configured as http://partner-ods:8080/api in the Spring environment property partnerOds.baseUrl . Detailed configuration like timeouts can be configured with default feign properties in the application.yaml or derived environment properties based on the name attribute of the org.springframework.cloud.openfeign.FeignClient annotation. The client is then available as bean in the Spring context.","title":"Http Client"},{"location":"web/#authentication-forwarding","text":"The client can be used within the SDA Platform to path through the received authentication header by adding a configuration: 1 2 3 4 5 6 7 8 9 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" , configuration = { AuthenticationPassThroughClientConfiguration . class } ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } AuthenticationPassThroughClientConfiguration will take the Authorization header from the current request context of the servlet and adds its value to the client request.","title":"Authentication forwarding"},{"location":"web/#trace-token","text":"The client can be used within the SDA Platform to pass through the received Trace-Token header by adding a configuration: 1 2 3 4 5 6 7 8 9 @FeignClient ( name = \"partnerOds\" , url = \"${partnerOds.baseUrl}\" , configuration = { SdaTraceTokenClientConfiguration . class } ) public interface OtherServiceClient { @GetMapping ( \"/partners\" ) List < Partner > getPartners (); } SdaTraceTokenClientConfiguration will take the Trace-Token header from the current request context of the servlet and adds its value to the client request. If no Trace-Token header is present in the current request context, the SdaTraceTokenClientConfiguration will generate a new Trace-Token and pass it to the following requests.","title":"Trace-Token"},{"location":"web/#oidc-client","text":"If the request context is not always existing, e.g. in cases where a technical user for service-to-service communication is required, the OidcClientRequestConfiguration will request the required OIDC authentication token with the client credentials flow using the configured \"oidc.client.issuer.uri\" , \"oidc.client.id\" and \"oidc.client.secret\" . If the current request context contains the Authorization header, the authentication pass-through will be applied instead.","title":"OIDC Client"},{"location":"web/#jax-rs-mapping","text":"If you would like to use JAX-RS based web annotations, you just need to apply the feign.jaxrs2.JAXRS2Contract.class to configurations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Path ( \"customers\" ) @FeignClient ( value = \"customerService\" , url = \"${customer.api.base.url}\" , configuration = { OidcClientRequestConfiguration . class , feign . jaxrs2 . JAXRS2Contract . class }) public interface CustomerServiceApi { @POST @Path ( \"/{customerId}/contracts\" ) @Consumes ( APPLICATION_JSON ) void addContract ( @PathParam ( \"customerId\" ) @NotBlank String customerId , Contract contract ); }","title":"JAX-RS Mapping"},{"location":"web/#configuration-properties_1","text":"oidc.client.enabled boolean Enables OIDC Authentication (Client Credentials Flow) for the configured clients. If enabled, provide a client id, secret and an issuer url. Example: true Default: false oidc.client.id string Client ID for the registration Example: oidcClient Default: `` oid.client.secret string Client secret of the registration. Example: s3cret Default: `` oidc.client.issuer.uri string URI that can either be an OpenID Connect discovery endpoint or an OAuth 2.0 Authorization Server Metadata endpoint defined by RFC 8414. Example: https://keycloak.sdadev.sda-se.io/auth/realms/exampleRealm Default: ``","title":"Configuration properties"},{"location":"web/#platform-client","text":"The Platform Client combines the authentication forwarding, trace token and OIDC configuration without the need to configure each individually. 1 2 3 4 5 6 7 @PlatformClient ( value = \"customerService\" , url = \"${customer.api.base.url}\" ) public interface CustomerServiceApi { // ... } It abstracts some configuration of the FeignClient and is then available as bean as well.","title":"Platform Client"},{"location":"web/#error-handling","text":"The sda-commons-web-starter provides a shared ApiError model, to provide a common response error structure for SDA-restful services.","title":"Error Handling"},{"location":"web/#usage","text":"Per default, the sda-commons-web-starter autoconfigures a global @ExceptionHandler(ApiException.class) as @ControllerAdvice . As a result, the exception handler is per default provided to every @Controller .","title":"Usage"},{"location":"web/#referencing-in-openapi","text":"To provide the common ApiError in the API, you need to reference the class as @Schema . 1 2 3 4 5 @ApiResponse( responseCode = \"422\", description = \"The request could not be processed due to invalid parameters. Details are provided in the error response.\", content = @Content(schema = @Schema(implementation = ApiError.class)))","title":"Referencing in OpenAPI"},{"location":"web/#throwing-apiexception","text":"When the ApiException is thrown the @ExceptionHandler automatically intercepts the exception and maps the related ResponseEntity . As the result, the controller returns the related http response code and the nested ApiError . 1 2 3 4 5 6 throw ApiException.builder() .httpCode(422) .title(\"Invalid input\") .detail(\"name\", \"name was not null\", \"NOT_NULL\") .cause(e) .build(); In this example the controller would return with http status 422 and body: 1 2 3 4 5 6 7 8 9 10 { \"title\" : \"Invalid input\" , \"invalidParams\" : [ { \"field\" : \"name\" , \"reason\" : \"name was not null\" , \"errorCode\" : \"NOT_NULL\" } ] }","title":"Throwing ApiException"},{"location":"web/#async","text":"The default Spring async task executor is autoconfigured to transfer the request attributes of the current request to the Thread running the asynchronous method.","title":"Async"},{"location":"web/#jackson","text":"Enables feature that make a Spring Boot service compliant with the SDA SE RESTful API Guide . So far this covers: - the tolerant reader pattern - consistent serialization of java.time.ZonedDateTime compatible to the type date-time of JSON-Schema . It is strongly recommended to use - java.time.LocalDate for dates without time serialized as 2018-09-23 - java.time.ZonedDateTime for date and times serialized as 2018-09-23T14:21:41+01:00 - java.time.Duration for durations with time resolution serialized as P1DT13M - java.time.Period for durations with day resolution serialized as P1Y2D All these types can be read and written in JSON as ISO 8601 formats. Reading java.time.ZonedDateTime is configured to be tolerant so that added nanoseconds or missing milliseconds or missing seconds are supported. @com.fasterxml.jackson.annotation.JsonFormat(pattern = \"...\") should not be used for customizing serialization because it breaks tolerant reading of formatting variants. If a specific field should be serialized with milliseconds, it must be annotated with @com.fasterxml.jackson.databind.annotation.JsonSerialize(using = Iso8601Serializer.WithMillis.class) . If a specific field should be serialized with nanoseconds, it must be annotated with @com.fasterxml.jackson.databind.annotation.JsonSerialize(using = Iso8601Serializer.WithNanos.class) Differences to the known SDA Dropwizard Commons configuration - java.time.ZonedDateTime fields are serialized with seconds by default. There is no other global configuration for java.time.ZonedDateTime serialization available. - Less modules are activated for foreign frameworks . Compared to SDA Dropwizard Commons, GuavaExtrasModule, JodaModule, and CaffeineModule are not registered anymore. - No documented customization of the global com.fasterxml.jackson.databind.ObjectMapper is available right now. - Support for HAL Links and embedding linked resources is not implemented. - Support for YAML is not implemented. - There is no support for field filters . Such filters have been barely used in the SDA SE.","title":"Jackson"},{"location":"web/#monitoring","text":"TODO PROMETHEUS Prometheus Metrics: http://{serviceURL}:{adminPort}/metrics/prometheus","title":"Monitoring"},{"location":"web/#default-properties","text":"1 2 3 4 5 # Metrics management.endpoints.web.path-mapping.prometheus = metrics/prometheus management.metrics.web.server.request.autotime.enabled = true management.endpoint.prometheus.enabled = true management.endpoint.metrics.enabled = true","title":"Default properties"},{"location":"web/#tracing","text":"Currently, tracing is leveraged by Sleuth in the Spring context. Spring Cloud Sleuth provides Spring Boot autoconfiguration for distributed tracing. Sleuth was built around Zipkin traces and so only supports forwarding them to Zipkin (Thrift via Brave) format for now. But since Jaeger supports Zipkin traces and the OpenTracing Jaeger Spring support is not heavily maintained, there is a need to stick with Sleuth. However, Spring Sleuth is compatible with OpenTracing, so we can use the standardized interfaces, hence the OpenTracing io.opentracing.Tracer is on classpath. Even if Jaeger supports the Zipkin B3 propagation format, Sleuth is forced to just use per default the W3C context propagation Default features are: Adds trace and span ids to the Slf4J MDC, so you can extract all the logs from a given trace or span in a log aggregator. Instruments common ingress and egress points from Spring applications (servlet filter, rest template, scheduled actions, message channels, feign client). The service name is derived from spring.application.name Generate and report Jaeger-compatible traces via HTTP. By default, it sends them to a Zipkin collector on localhost (port 9411). Configure the location of the service using spring.zipkin.base-url . spring.zipkin.base.url string Base url to Zipkin or Zipkin Collector of Jaeger instance. In case of Jaeger, the Zipkin collector must be enabled manually. Example: http://jaeger:9411 Default: http://localhost:9411 spring.zipkin.enabled boolean For testing purposes it's may required to disable tracing. Example: false Default: true","title":"Tracing"},{"location":"web/#default-properties_1","text":"1 2 spring.sleuth.propagation.type = W3C, B3 spring.sleuth.opentracing.enabled = true","title":"Default properties"},{"location":"web/#health-checks-actuator","text":"Enable features that make a Spring Boot service compliant with the SDA SE Health Checks . Configures the Spring Boot Actuator to be accessible on root path / at default management port 8081 . The following endpoints are provided at the admin management endpoint: Liveness: http://{serviceURL}:{adminPort}/healthcheck/liveness Readiness: http://{serviceURL}:{adminPort}/healthcheck/readiness The readiness group contains the following indicators: ReadinessStateHealthIndicator MongoHealthIndicator , if auto-configured. OpenPolicyAgentHealthIndicator if OPA is enabled for authentication To overwrite the defaults HealthIndicator of the readiness group, you can overwrite the property source: 1 management.endpoint.health.group.readiness.include = readinessState, customCheck Custom health indicators can be easily added to the application context: 1 2 3 4 5 6 7 @Component public class CustomHealthIndicator implements HealthIndicator { @Override public Health health () { return new Health . Builder (). up (). build (); } } The custom health indicator will be available under /healthcheck/custom which is resolved by the prefix of the HealthIndicator implementing component.","title":"Health Checks / Actuator"},{"location":"web/#default-properties_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Actuator management.server.port = 8081 management.server.servlet.context-path = / management.endpoints.web.base-path = / management.endpoints.web.exposure.include = * management.endpoints.enabled-by-default = false # Healthcheck management.endpoint.health.enabled = true management.endpoints.web.path-mapping.health = healthcheck management.endpoint.health.probes.enabled = true # Add the required auto configured health indicators which are supported in org.sdase.commons.spring # See https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints.health.auto-configured-health-indicators # to see the available indicators. If an included HealthIndicator is not autoconfigured, it will be automatically ignored management.endpoint.health.group.readiness.include = readinessState, mongo management.endpoint.health.show-details = always management.endpoint.health.show-components = always","title":"Default properties"},{"location":"web/#logging","text":"The Spring Boot default logging is enabled. Logs are printed to standard out. ENABLE_JSON_LOGGING=true as environment variable or -Denable.json.logging=true as JVM parameter enables output as JSON for structured logs used in log aggregation tools. To enable JSON logging in application.(properties/yaml) , logging.config=classpath:org/sdase/commons/spring/boot/web/logging/logback-json.xml may be used.","title":"Logging"},{"location":"web/#metadata-context","text":"If you want to make use of the data in the metadata context, you should read the dedicated documentation . If your service is required to support the metadata context but is not interested in the data, continue here: Services that use the sda-spring-boot-commons: - can access the current MetadataContext in their implementation - will automatically load the context from incoming HTTP requests into the thread handling the request, if you register MetadataContextConfiguration - will automatically load the context from consumed Kafka messages into the thread handling the message and the error when handling the message fails when the consumer is configured with one of the provided SdaKafkaConsumerConfiguration - will automatically propagate the context to other services via HTTP when using a platform client that uses the MetadataContextClientConfiguration configuration, e.g: - ```java @FeignClient( value = \"name\", url = \" http://your-api-url \", configuration = { MetadataContextClientConfiguration.class }) public interface ClientWithMetadataConfiguration { 1 2 3 4 @GetMapping(\"/metadata-hello\") Object getSomething(); } ``` will automatically propagate the context in produced Kafka messages when the producer is created with SdaKafkaProducerConfiguration are configurable by the property or environment variable METADATA_FIELDS to be aware of the metadata used in a specific environment Services that interrupt a business process should persist the context from MetadataContext.detachedCurrent() and restore it with MetadataContext.createContext(\u2026) when the process continues. Interrupting a business process means that processing is stopped and continued later in a new thread or even another instance of the service. Most likely, this will happen when a business entity is stored based on a request and loaded later for further processing by a scheduler or due to a new user interaction. In this case, the DetachedMetadataContext must be persisted along with the entity and recreated when the entity is loaded. The DetachedMetadataContext can be defined as field in any MongoDB entity. For services that handle requests or messages in parallel, the metadata context attributes will be automatically transferred to the new threads, if @Async is used.","title":"Metadata Context"}]}